{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f4b008b",
   "metadata": {},
   "source": [
    "# Data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ba04f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader,random_split,TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import confusion_matrix, f1_score, ConfusionMatrixDisplay\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.core import UTCDateTime\n",
    "from obspy import read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc2a125",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8c15417c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4364 Trace(s) in Stream:\n",
      "\n",
      "IU.ADK.00.LHZ | 2003-07-27T05:25:31.848146Z - 2003-07-27T07:25:21.848146Z | 0.1 Hz, 720 samples\n",
      "...\n",
      "(4362 other traces)\n",
      "...\n",
      "IU.YSS.00.LHZ | 2003-05-26T18:23:29.298340Z - 2003-05-26T20:23:19.298340Z | 0.1 Hz, 720 samples\n",
      "\n",
      "[Use \"print(Stream.__str__(extended=True))\" to print all Traces]\n",
      "4364\n"
     ]
    }
   ],
   "source": [
    "# read data \n",
    "from glob import glob\n",
    "file_list = glob(\"*.mseed\")\n",
    "for i,file in enumerate(file_list):\n",
    "    if i ==0:\n",
    "        st = read(file)\n",
    "    else:\n",
    "        st += read(file)\n",
    "print(st)\n",
    "\n",
    "# get the total number of traces in st\n",
    "num_of_traces= (len(st))\n",
    "print(num_of_traces)\n",
    "\n",
    "# 720 data points in a single trace\n",
    "for trace in st:\n",
    "    samples = len(trace)\n",
    "#     print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7ecb7b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# st[30].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "93ddb0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set timer\n",
    "time_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14c61ab",
   "metadata": {},
   "source": [
    "# Dataset and Sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "38f453a7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ApterStDataset(Dataset):\n",
    "    def __init__(self,base_size = 360,size = 10,drop_last=True,mode=\"train\"):\n",
    "        #mode train,test,val\n",
    "        self.st = np.vstack([st]) # st(2794,720)\n",
    "        self.st = preprocessing.scale(self.st)\n",
    "        if mode == \"train\":\n",
    "            self.st = self.st[0:int(len(self.st)*0.8)] # train mode : use 0-0.8 as train data\n",
    "        elif mode==\"test\":\n",
    "            self.st = self.st[int(len(self.st)*0.8):int(len(self.st)*0.9)] # test mode: use 0.8-0.9 as test data\n",
    "        elif mode==\"val\":\n",
    "            self.st = self.st[int(len(self.st)*0.9):int(len(self.st))] # val mode: use 0.9-1.0 as test data\n",
    "        else:\n",
    "            raise \"mode error\"\n",
    "        \n",
    "        self.size = size # moving window size\n",
    "        self.drop_last = drop_last # drop the last batch if the no. of data less than size\n",
    "        self.all_feture = self.init_all_feture(size = size,drop_last=drop_last,base_size=base_size) \n",
    "    \n",
    "    def init_all_feture(self,size,base_size,drop_last=True):\n",
    "        all_feture = []\n",
    "        for i in self.st:      \n",
    "            for j in range(base_size,720+size,size):\n",
    "                temp_st = i[j-base_size:j] # moving range\n",
    "                if j <= 360:\n",
    "                    label = np.array([0]) # non-seismic event labelling \n",
    "                else:\n",
    "                    label = np.array([1]) # seismic event labelling \n",
    "                if drop_last:   \n",
    "                    if len(temp_st) == base_size:\n",
    "                        all_feture.append((temp_st,label))\n",
    "                else:\n",
    "                    all_feture.append((temp_st,label))\n",
    "        return all_feture\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_feture)\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        feture = torch.from_numpy(self.all_feture[idx][0])\n",
    "        # feture = feture.resize(batch)\n",
    "        feture = feture.unsqueeze(1)  # add 1 dimension -> [size,1]\n",
    "        label = torch.from_numpy(self.all_feture[idx][1])\n",
    "        label = label.to(torch.long) # to int64\n",
    "        return feture,label\n",
    "\n",
    "#ApterStDataset\n",
    "# asd = ApterStDataset(size=10,drop_last=True,mode=\"val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8809bb4f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[ 0.0175],\n",
      "         [ 0.0089],\n",
      "         [ 0.0053],\n",
      "         ...,\n",
      "         [ 0.0123],\n",
      "         [ 0.0144],\n",
      "         [ 0.0065]],\n",
      "\n",
      "        [[ 0.0101],\n",
      "         [ 0.0185],\n",
      "         [ 0.0150],\n",
      "         ...,\n",
      "         [-0.0154],\n",
      "         [-0.0193],\n",
      "         [-0.0218]],\n",
      "\n",
      "        [[-0.0306],\n",
      "         [-0.0222],\n",
      "         [-0.0134],\n",
      "         ...,\n",
      "         [-0.0181],\n",
      "         [-0.0184],\n",
      "         [-0.0140]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0101],\n",
      "         [-0.0108],\n",
      "         [-0.0215],\n",
      "         ...,\n",
      "         [ 0.0146],\n",
      "         [ 0.0106],\n",
      "         [ 0.0014]],\n",
      "\n",
      "        [[-0.0207],\n",
      "         [-0.0152],\n",
      "         [-0.0119],\n",
      "         ...,\n",
      "         [-0.0079],\n",
      "         [-0.0182],\n",
      "         [-0.0305]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [-0.0167],\n",
      "         [-0.0172],\n",
      "         ...,\n",
      "         [-0.0081],\n",
      "         [ 0.0183],\n",
      "         [ 0.0156]]], dtype=torch.float64), tensor([[0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1]])]\n"
     ]
    }
   ],
   "source": [
    "batch = 20\n",
    "base_size = 180\n",
    "size = 10\n",
    "\n",
    "train_asd = ApterStDataset(base_size=base_size,size=size,drop_last=True,mode=\"train\")\n",
    "test_asd = ApterStDataset(base_size=base_size,size=size,drop_last=True,mode=\"test\")\n",
    "val_asd = ApterStDataset(base_size=base_size,size=size,drop_last=True,mode=\"val\")\n",
    "\n",
    "#DataLoader\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train_asd,\n",
    "    batch_size=batch,\n",
    "    shuffle = True, # shuffle the data\n",
    "    drop_last = True, # drop last batch\n",
    "    num_workers=0      \n",
    ")\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "    test_asd,\n",
    "    batch_size=batch,\n",
    "    shuffle = True, # shuffle the data\n",
    "    drop_last = True, # drop last batch\n",
    "    num_workers=0     \n",
    ")\n",
    "val_dl = torch.utils.data.DataLoader(\n",
    "    val_asd,\n",
    "    batch_size=batch,\n",
    "    shuffle = True, # shuffle the data\n",
    "    drop_last = True, # drop last batch\n",
    "    num_workers=0      \n",
    ")\n",
    "for i,data in enumerate(test_dl):\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7b479bb3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9600"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9a302c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1199"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cbc5f150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1201"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c981b3c0",
   "metadata": {},
   "source": [
    "# The 1D CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6f0e7c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2])\n"
     ]
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=base_size, out_channels=100, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=100, out_channels=50, kernel_size=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=50, out_features=40)\n",
    "        self.fc2 = nn.Linear(in_features=40, out_features=30)\n",
    "        self.out = nn.Linear(in_features=30, out_features=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "       \n",
    "        x = x.flatten(1) # flatten the tensor starting at dimension 1\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     cnn_cuda=cnn_cuda.cuda()\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    cnn = Network()\n",
    "    input = torch.ones(batch, base_size, 1)\n",
    "    output = cnn(input)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "499fb4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 180, 1])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.conv1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3b95da8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 100, 1])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.conv2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3f9d12cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 50])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fc1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "443ad258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 40])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fc2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a96d6f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.out.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7969127e",
   "metadata": {},
   "source": [
    "# Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c9096db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for training model\n",
    "# total No. of traing\n",
    "total_train_step = 0\n",
    "\n",
    "# total No. of testing\n",
    "total_test_step = 0\n",
    "\n",
    "# Loss function \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "cnn = Network()\n",
    "if torch.cuda.is_available():\n",
    "    loss_fn = loss_fn.cuda()\n",
    "    cnn = cnn.to(\"cuda\")\n",
    "    \n",
    "# Optimizer\n",
    "learning_rate = 0.0001\n",
    "# optimizer = torch.optim.SGD(cnn.parameters(), lr = learning_rate, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "# epoch\n",
    "epoch = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5ae8bc9e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# cnn.load_state_dict(torch.load(\"best_network.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e78f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuxiaoyu/opt/anaconda3/envs/python3_7/lib/python3.7/site-packages/torch/_tensor.py:586: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1,Train Loss: 0.0074,Train Acc: 0.94,Test Loss: 0.0016,Test Acc: 0.99\n",
      "epoch:2,Train Loss: 0.0019,Train Acc: 0.99,Test Loss: 0.0015,Test Acc: 0.99\n",
      "epoch:3,Train Loss: 0.0016,Train Acc: 0.99,Test Loss: 0.0015,Test Acc: 0.99\n",
      "epoch:4,Train Loss: 0.0014,Train Acc: 0.99,Test Loss: 0.0014,Test Acc: 0.99\n",
      "epoch:5,Train Loss: 0.0012,Train Acc: 0.99,Test Loss: 0.0013,Test Acc: 0.99\n",
      "epoch:6,Train Loss: 0.0011,Train Acc: 0.99,Test Loss: 0.0013,Test Acc: 0.99\n",
      "epoch:7,Train Loss: 0.0010,Train Acc: 0.99,Test Loss: 0.0012,Test Acc: 0.99\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_acces = []\n",
    "test_losses = []\n",
    "test_acces = []\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    # training\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    cnn.train()  # training mode\n",
    "\n",
    "    for data in train_dl:\n",
    "        train_x, train_y = data\n",
    "        train_y = train_y.resize(batch)\n",
    "        if torch.cuda.is_available():\n",
    "            train_x = train_x.cuda()\n",
    "            train_y = train_y.cuda()\n",
    "        train_x = train_x.to(torch.float)\n",
    "        outputs = cnn(train_x)          # use train_x as inputs to the model\n",
    "        loss = loss_fn(outputs,train_y) # calculate the loss between outputs and train_y\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # record train loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # train accuracy\n",
    "        train_accuracy = (outputs.argmax(1) == train_y).sum()\n",
    "        train_acc += train_accuracy.cpu()\n",
    "\n",
    "    train_losses.append(train_loss/len(train_asd))\n",
    "    train_acces.append(train_acc/len(train_asd))\n",
    "\n",
    "    # testing\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    cnn.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_dl:\n",
    "            test_x,test_y = data\n",
    "            test_y = test_y.resize(batch)\n",
    "            if torch.cuda.is_available():\n",
    "                test_x = test_x.cuda()\n",
    "                test_y = test_y.cuda()\n",
    "            test_x = test_x.to(torch.float)\n",
    "\n",
    "            outputs = cnn(test_x)\n",
    "            loss = loss_fn(outputs, test_y)\n",
    "\n",
    "            # record train loss\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # test accuracy\n",
    "            test_accuracy = (outputs.argmax(1) == test_y).sum()\n",
    "            test_acc += test_accuracy.cpu()\n",
    "\n",
    "        test_losses.append(test_loss/len(test_asd))\n",
    "        test_acces.append(test_acc/len(test_asd))\n",
    "    print(\"epoch:{},Train Loss: {:.4f},Train Acc: {:.2f},Test Loss: {:.4f},Test Acc: {:.2f}\".format(i+1,\n",
    "          train_loss/len(train_asd),\n",
    "          train_acc/len(train_asd),\n",
    "          test_loss/len(test_asd),\n",
    "          test_acc/len(test_asd)))\n",
    "\n",
    "    torch.save(cnn, 'best_cnn.pth')  # save the network\n",
    "    torch.save(cnn.state_dict(), 'cnn_params.pth')   # only save parameters\n",
    "\n",
    "\n",
    "#     # early stopping\n",
    "#     early_stopping(test_loss, cnn)\n",
    "\n",
    "#     if early_stopping.early_stop:\n",
    "#         print(\"Early stopping\")\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a5d6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_end = time.time()\n",
    "time_c= time_end - time_start\n",
    "print('time cost', time_c, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede67fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ploting training and testing loss\n",
    "plt.plot(train_losses,label='training loss')\n",
    "plt.plot(test_losses,label='testing loss')\n",
    "plt.title(\"Training and Testing Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc = \"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2260b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting training and testing acc\n",
    "plt.plot(train_acces,label='training accuracy')\n",
    "plt.plot(test_acces,label='testing accuracy')\n",
    "plt.title(\"Training and Testing Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f8c925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn.eval()\n",
    "# x1 = []\n",
    "# x2 = []\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for data in val_dl:\n",
    "#         val_x,val_y = data\n",
    "# #         print(val_x)\n",
    "# #         print(val_y)\n",
    "#         val_y = val_y.resize(batch)\n",
    "#         val_x = val_x.to(torch.float)\n",
    "\n",
    "#         outputs = cnn(val_x)\n",
    "#         outputs = outputs.argmax(1)\n",
    "#         val_x = val_x.cpu()\n",
    "        \n",
    "#         x1.append(val_x[outputs == 1].squeeze()) # seismic event\n",
    "#         x2.append(val_x[outputs == 0].squeeze()) # non seismic event\n",
    "#         y_pred.append(outputs)  # classfied values\n",
    "#         y_true.append(val_y)    # true values\n",
    "        \n",
    "#     x1 = np.vstack(x1)\n",
    "#     x2 = np.vstack(x2)    \n",
    "# #     y_pred = np.vstack(y_pred)\n",
    "# #     y_true = np.vstack(y_true)\n",
    "    \n",
    "#     print(x1.shape)\n",
    "#     print(x2.shape)\n",
    "#     print(type(y_pred))\n",
    "#     print(type(y_true))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13666d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plotting the classification results \n",
    "# tt = np.linspace(0, base_size, num = base_size)\n",
    "# print(tt.shape)\n",
    "# print(x1.shape)\n",
    "# print(x2.shape)\n",
    "\n",
    "# # before event\n",
    "# plt.plot(tt, x1[0,:], color = 'skyblue',label='Seismic event', linestyle='--')   \n",
    "# plt.plot(tt, x1[50,:],color = 'skyblue' , linestyle='--')            \n",
    "# plt.plot(tt, x1[99,:],color = 'skyblue', linestyle='--')\n",
    "\n",
    "# # after event \n",
    "# plt.plot(tt, x2[0,:], color = 'maroon',label='Non-Seismic event')   \n",
    "# plt.plot(tt, x2[50,:], color = 'maroon')             \n",
    "# plt.plot(tt, x2[99,:], color = 'maroon') \n",
    "\n",
    "# plt.legend(loc= \"upper left\")\n",
    "# plt.title(\"Seismograms Classified\")\n",
    "# plt.style.use('seaborn')\n",
    "# plt.xlabel(\"Time\")\n",
    "# plt.ylabel(\"Frequncy\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffcb14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # \"\"\"classified results\"\"\"\n",
    "# cnn.eval()\n",
    "# test_input = test_asd.st[1]\n",
    "# all_test_x = []\n",
    "# all_predict = []\n",
    "# for i in range(0, len(test_input), base_size):\n",
    "#     temp_input = test_input[i:i + base_size]\n",
    "#     if len(temp_input) != base_size:\n",
    "#         continue\n",
    "#     all_test_x.append(temp_input)\n",
    "#     temp_input = torch.from_numpy(temp_input)\n",
    "#     temp_input = temp_input.view(1, base_size, 1)\n",
    "\n",
    "#     if torch.cuda.is_available():\n",
    "#         temp_input = temp_input.cuda()\n",
    "#     temp_input = temp_input.to(torch.float)\n",
    "#     outputs = cnn(temp_input)\n",
    "#     outputs = outputs.argmax(1)\n",
    "#     all_predict.append(torch.flatten(torch.tile(outputs.cpu().view(-1, 1), (1, base_size))))\n",
    "# all_test_x = np.concatenate(all_test_x)\n",
    "# all_predict = np.concatenate(all_predict)\n",
    "\n",
    "# x_data = list(all_predict)\n",
    "# y_data = list(all_test_x)\n",
    "# color_list = []\n",
    "\n",
    "# flag = False\n",
    "# for i, predict in enumerate(x_data):\n",
    "\n",
    "#     if flag == True and predict == 0:\n",
    "#         end = i\n",
    "#         color_list.append(opts.MarkAreaItem(name=\"1\", x=(start, end)), )\n",
    "#     elif flag == False and predict == 1:\n",
    "#         start = i\n",
    "#     if predict == 1:\n",
    "#         flag = True\n",
    "#     else:\n",
    "#         flag = False\n",
    "#     if i == len(x_data) - 1:\n",
    "#         color_list.append(opts.MarkAreaItem(name=\"1\", x=(start, i + 1)), )\n",
    "\n",
    "# x_data = [str(i) for i in range(len(x_data))]\n",
    "\n",
    "# line = (\n",
    "#     Line()\n",
    "#         .add_xaxis(x_data)\n",
    "#         .add_yaxis(\n",
    "#         series_name=\"\",\n",
    "#         y_axis=y_data,\n",
    "#         label_opts=opts.LabelOpts(is_show=False),\n",
    "#                 linestyle_opts=opts.LineStyleOpts(width=2),\n",
    "#     )\n",
    "#         .set_global_opts(\n",
    "#         title_opts=opts.TitleOpts(title=\"Bar-DataZoom（slider）\"),\n",
    "#                     datazoom_opts=opts.DataZoomOpts(),\n",
    "#     )\n",
    "#         .set_series_opts(\n",
    "#         markarea_opts=opts.MarkAreaOpts(\n",
    "#             data=color_list\n",
    "#         )\n",
    "#     )\n",
    "# )\n",
    "# line.render_notebook()\n",
    "# # line.render(\"line_style_and_item_style_60.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt = np.linspace(0, 720, num = 720)\n",
    "\n",
    "# plt.subplot(5,1,5)\n",
    "# plt.subplot(5,1,1)\n",
    "# plt.plot(tt, st[0].data, color = 'skyblue',label='Seismic event')   \n",
    "# plt.title(\"Raw Siesmic Signals\")\n",
    "# plt.subplot(5,1,2)\n",
    "# plt.plot(tt, st[1].data, color = 'skyblue',label='Seismic event')   \n",
    "\n",
    "# plt.subplot(5,1,3)\n",
    "# plt.plot(tt, st[2].data, color = 'skyblue',label='Seismic event') \n",
    "\n",
    "# plt.subplot(5,1,4)\n",
    "# plt.plot(tt, st[3].data, color = 'skyblue',label='Seismic event')   \n",
    "\n",
    "# plt.subplot(5,1,5)\n",
    "# plt.plot(tt, st[4].data, color = 'skyblue',label='Seismic event') \n",
    "\n",
    "# plt.legend(loc= \"upper left\")\n",
    "# plt.style.use('seaborn')\n",
    "# plt.xlabel(\"Time\")\n",
    "# plt.ylabel(\"Frequncy\")\n",
    "# plt.subplots_adjust(left=None, bottom=None, right=None, top=None,\n",
    "#                 wspace=0, hspace=0.5)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e738fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
